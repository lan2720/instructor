{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List\n",
    "import openai\n",
    "import instructor\n",
    "\n",
    "openai.api_base = \"https://futu-002-caeast-001.openai.azure.com/\"\n",
    "openai.api_key = \"5d050ffec2b94f5eb43c54c80149561e\"\n",
    "openai.api_version = \"2023-07-01-preview\"\n",
    "openai.api_type = \"azure\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 发现某个Object的更多其他property，可选属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'result': {'age': 0, 'name': 'John Doe', 'role': 'best friend', 'properties': [{'key': 'Education', 'value': 'Stanford University'}, {'key': 'Spouse', 'value': 'Bella'}]}, 'error': False, 'message': None}\n"
     ]
    }
   ],
   "source": [
    "instructor.patch()\n",
    "\n",
    "class Property(BaseModel):\n",
    "    key: str\n",
    "    value: str\n",
    "\n",
    "class UserDetail(BaseModel):\n",
    "    age: int\n",
    "    name: str\n",
    "    role: Optional[str] = Field(default=None)\n",
    "    properties: List[Property] = Field(..., description=\"Extract any other properties that might be relevant\")\n",
    "    \n",
    "class MaybeUser(BaseModel):\n",
    "    result: Optional[UserDetail] = Field(default=None)\n",
    "    error: bool = Field(default=False)\n",
    "    message: Optional[str] = Field(default=None)\n",
    "    def _bool_(self):\n",
    "        return self.result is not None\n",
    "    \n",
    "def get_user_detail(input_text: str) -> MaybeUser:\n",
    "    return openai.ChatCompletion.create(\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \n",
    "             \"content\": f\"Extract {input_text}\"\n",
    "             }\n",
    "        ],\n",
    "        engine=\"gpt-4\",\n",
    "        temperature=0.,\n",
    "        response_model=MaybeUser\n",
    "    )\n",
    "texts = [\"Jason is a 25 years old scientist\", \n",
    "         \"Unknown user\",\n",
    "         \"John Doe is my best friend. He graduated from Stanford University. His wife is Bella. She is so loved with him.\"]\n",
    "for text in texts[-1:]:\n",
    "    user = get_user_detail(text)\n",
    "    print(user.model_dump())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将search query拆解为对多个search agent的不同query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/data/home/jarvixwang/project/instructor/notebook/maybe_usage.ipynb 单元格 5\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balgo21/data/home/jarvixwang/project/instructor/notebook/maybe_usage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m     \u001b[39mawait\u001b[39;00m asyncio\u001b[39m.\u001b[39mgather(\u001b[39m*\u001b[39m[q\u001b[39m.\u001b[39mexecute() \u001b[39mfor\u001b[39;00m q \u001b[39min\u001b[39;00m queries\u001b[39m.\u001b[39mtasks])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balgo21/data/home/jarvixwang/project/instructor/notebook/maybe_usage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m loop \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mget_event_loop()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Balgo21/data/home/jarvixwang/project/instructor/notebook/maybe_usage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m loop\u001b[39m.\u001b[39;49mrun_until_complete(execute_queries(queries))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balgo21/data/home/jarvixwang/project/instructor/notebook/maybe_usage.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=61'>62</a>\u001b[0m loop\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/instructor/lib/python3.11/asyncio/base_events.py:629\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Run until the Future is done.\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \n\u001b[1;32m    620\u001b[0m \u001b[39mIf the argument is a coroutine, it is wrapped in a Task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[39mReturn the Future's result, or raise its exception.\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[0;32m--> 629\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_running()\n\u001b[1;32m    631\u001b[0m new_task \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m futures\u001b[39m.\u001b[39misfuture(future)\n\u001b[1;32m    632\u001b[0m future \u001b[39m=\u001b[39m tasks\u001b[39m.\u001b[39mensure_future(future, loop\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/instructor/lib/python3.11/asyncio/base_events.py:588\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_running\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    587\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_running():\n\u001b[0;32m--> 588\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mThis event loop is already running\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    589\u001b[0m     \u001b[39mif\u001b[39;00m events\u001b[39m.\u001b[39m_get_running_loop() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    590\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    591\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mCannot run the event loop while another loop is running\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from datetime import datetime\n",
    "import enum\n",
    "from instructor import OpenAISchema\n",
    "from instructor.dsl import MultiTask\n",
    "# instructor.patch()\n",
    "\n",
    "class SearchType(str, enum.Enum):\n",
    "    VIDEO = \"video\"\n",
    "    EMAIL = \"email\"\n",
    "\n",
    "class Search(OpenAISchema):\n",
    "    title: Optional[str] = Field(default=None, description=\"Title of the request\")\n",
    "    query: Optional[str] = Field(description=\"Query to search for relevant content\")\n",
    "    type: SearchType = Field(description=\"Type of search\")\n",
    "    \n",
    "    async def execute(self):\n",
    "        print(f\"Searching for `{self.title}` with query `{self.query}` using `{self.type}`\")\n",
    "        # print(\"当前正在执行\", self.name, f\"搜索类型: {self.type}\")\n",
    "\n",
    "# 原本此处是BaseModel现在换成OpenAISchema\n",
    "# class MultiSearch(OpenAISchema):\n",
    "#     tasks: List[Search]\n",
    "MultiSearch = MultiTask(Search)\n",
    "    # async def execute(self):\n",
    "    #     return await asyncio.gather(*[search.execute() for search in self.searches])\n",
    "\n",
    "def segment(data: str) -> MultiSearch:\n",
    "    \"\"\"segment是action, 接受到某个query时需要AI进行segment操作\n",
    "        希望AI操作完返回MultiSearch的object, 然后就可以对这个object进行.execute()让多个query同时执行\n",
    "    Args:\n",
    "        data (str): _description_\n",
    "\n",
    "    Returns:\n",
    "        MultiSearch: _description_\n",
    "    \"\"\"\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        engine=\"gpt-4\",\n",
    "        temperature=0.,\n",
    "        functions=[MultiSearch.openai_schema],\n",
    "        function_call={\"name\": MultiSearch.openai_schema[\"name\"]},\n",
    "        # response_model=MultiSearch,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \n",
    "             \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \n",
    "             \"content\": f\"Consider the data below:\\n{data} and segment it into multiple search queries\"},\n",
    "        ],\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    return MultiSearch.from_response(completion)\n",
    "    \n",
    "query = \"在youtube上播放今天的热门视频，然后，帮我发送一封生日祝福邮件给老板\"\n",
    "query = \"Please send me the video from last week about the investment case study and also documents about your GDPR policy?\"\n",
    "queries = segment(query)\n",
    "# queries.execute()\n",
    "async def execute_queries(queries: MultiSearch):\n",
    "    await asyncio.gather(*[q.execute() for q in queries.tasks])\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(execute_queries(queries))\n",
    "loop.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "instructor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
